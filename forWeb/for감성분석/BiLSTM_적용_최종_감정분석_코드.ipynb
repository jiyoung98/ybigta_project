{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM 적용-최종 감정분석 코드.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OQgWyj6hKdZ"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6mNa9klXMyO",
        "outputId": "c3e893f1-b478-45b5-c6c6-062059fa2180"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DwLIhLGiIv7",
        "outputId": "05351d7a-c4ca-421b-e0f8-101884fae12e"
      },
      "source": [
        "!pip install konlpy \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2gokgv_hK7l"
      },
      "source": [
        "tokenizer = Tokenizer(5542)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkdbvhFmhK-F"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/Ybigta/신입기수 프로젝트/감성분석 모델링 추가(Bi-LSTM, Attention)/wordIndex(BiLSTM2).json') as json_file:\n",
        "  word_index = json.load(json_file)\n",
        "  tokenizer.word_index = word_index\n",
        "\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Ybigta/신입기수 프로젝트/감성분석 모델링 추가(Bi-LSTM, Attention)/BiLSTM_model(sigmoid).h5')"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfJfNA0CiDBQ"
      },
      "source": [
        "okt = Okt()"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVgLwo9Vii38"
      },
      "source": [
        "max_len=30"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CirbA4TrrnrH",
        "outputId": "fa41ffdb-715c-4242-8d35-b8981764b251"
      },
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\r\n",
        "\r\n",
        "from pykospacing import spacing\r\n"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-idfsx8yc\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-idfsx8yc\n",
            "Requirement already satisfied (use --upgrade to upgrade): pykospacing==0.4 from git+https://github.com/haven-jeon/PyKoSpacing.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: tensorflow==2.4.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.4) (2.4.0)\n",
            "Requirement already satisfied: keras>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.4) (2.4.3)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.4) (2.10.0)\n",
            "Requirement already satisfied: argparse>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.4) (1.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (3.12.4)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (0.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (0.2.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (0.3.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.4.3->pykospacing==0.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.4.3->pykospacing==0.4) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow==2.4.0->pykospacing==0.4) (53.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.27.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.3.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (4.7.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.4.0)\n",
            "Building wheels for collected packages: pykospacing\n",
            "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykospacing: filename=pykospacing-0.4-cp37-none-any.whl size=2255638 sha256=f55221ca43a0e19f7d14e55f91d2a1dc6f3235524207db39e99e1cc44ed51725\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i25p88ll/wheels/4d/45/58/e26cb2b7f6a063d234158c6fd1e5700f6e15b99d67154340ba\n",
            "Successfully built pykospacing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J67PWF2rnut",
        "outputId": "1404deae-54e8-43b0-f1de-7b33fc5f94f0"
      },
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git\r\n",
        "\r\n",
        "from hanspell import spell_checker\r\n",
        "def grammar_check(text):\r\n",
        "  spelled_sent = spell_checker.check(text)\r\n",
        "  hanspell_sent = spelled_sent.checked\r\n",
        "  return hanspell_sent"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-pj52fpdp\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-pj52fpdp\n",
            "Requirement already satisfied (use --upgrade to upgrade): py-hanspell==1.1 from git+https://github.com/ssut/py-hanspell.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-cp37-none-any.whl size=4854 sha256=ce631964e7e99f87c25e119c139330fb798449e77bbe51885be73aa62bb97c28\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-11on8je2/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588\n",
            "Successfully built py-hanspell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH8ABCEWrnwt"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&' \r\n",
        "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\",\r\n",
        "                 \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', \r\n",
        "                 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi'} \r\n",
        "\r\n",
        "def clean_punc(text, punct, mapping): \r\n",
        "  for p in mapping: \r\n",
        "    text = text.replace(p, mapping[p]) \r\n",
        "  for p in punct: \r\n",
        "    text = text.replace(p, f' {p} ') \r\n",
        "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''} \r\n",
        "  for s in specials: \r\n",
        "    text = text.replace(s, specials[s]) \r\n",
        "   \r\n",
        "  return text.strip() \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def clean_text(texts): \r\n",
        "  corpus = [] \r\n",
        "  for i in range(0, len(texts)): \r\n",
        "    review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '',str(texts[i])) #remove punctuation \r\n",
        "    review = re.sub(r'\\d+','', str(texts[i]))# remove number \r\n",
        "    review = review.lower() #lower case \r\n",
        "    review = re.sub(r'\\s+', ' ', review) #remove extra space \r\n",
        "    review = re.sub(r'<[^>]+>','',review) #remove Html tags \r\n",
        "    review = re.sub(r'\\s+', ' ', review) #remove spaces \r\n",
        "    review = re.sub(r\"^\\s+\", '', review) #remove space from start \r\n",
        "    review = re.sub(r'\\s+$', '', review) #remove space from the end \r\n",
        "    review = re.sub(r'♥','',review)\r\n",
        "    review = re.sub(r'~','',review)\r\n",
        "    review = re.sub(r'&','',review)\r\n",
        "    review = re.sub(r'😱','',review)\r\n",
        "    corpus.append(review) \r\n",
        "  return corpus\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# removing emoji\r\n",
        "\r\n",
        "def rmEmoji(text):\r\n",
        "  review = text.encode('utf-8', 'ignore').decode('utf-8')\r\n",
        "  return review\r\n",
        "\r\n",
        "def rmEmoji_ascii(inputString):\r\n",
        "  review = example.encode('ascii','ignore').decode('ascii')\r\n",
        "  return review\r\n"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9djMfDyrq1h"
      },
      "source": [
        ""
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c5QLeluqgBH",
        "outputId": "68602621-fd0e-4c5b-a284-63d613e1511c"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.corpus import stopwords \r\n",
        "from nltk.tokenize import word_tokenize \r\n",
        "# NLTK Data 다운\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "stop_words = open('/content/drive/MyDrive/Ybigta/korean_stopwords.txt').read()\r\n",
        "\r\n",
        "\r\n",
        "# 위의 불용어는 명사가 아닌 단어 중에서 저자가 임의로 선정한 것으로 실제 의미있는 선정 기준이 아님\r\n",
        "stop_words=stop_words.split('\\n')"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3pPRegdj2u0"
      },
      "source": [
        "def tokenize_tagged(text):\r\n",
        "\r\n",
        "  temp_X = okt.pos(text, norm=True, stem=True) # 토큰화\r\n",
        "  temp_X = [word for word in temp_X if not word in stop_words] # 불용어 제거\r\n",
        "  return ['/'.join(t) for t in temp_X]"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83oAE8U3j2x0"
      },
      "source": [
        ""
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrX6Olh_j27n",
        "outputId": "bb8544d7-31c7-4874-b60d-c283e5dc3aa8"
      },
      "source": [
        "tokenize_tagged(\"안녕 만나서 반가워\")"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['안녕/Noun', '만나다/Verb', '반갑다/Adjective']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxniStEhiDDd"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  text1 = clean_punc(new_sentence, punct, punct_mapping)\n",
        "  text2 = ''.join(clean_text(text1))\n",
        "  text3 = spacing(text2)\n",
        "  text4 = grammar_check(text3)\n",
        "  text_ = tokenize_tagged(text4)\n",
        "\n",
        "  #new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
        "  print(text_)\n",
        "  #new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
        "  #print(new_sentence)\n",
        "  encoded = tokenizer.texts_to_sequences([text_]) # 정수 인코딩\n",
        "  print(encoded)\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
        "  print(pad_new)\n",
        "  score = float(model.predict(pad_new)) # 예측\n",
        "  \n",
        "  print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
        "  #if(score > 0.5):\n",
        "    #print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
        "  #else:\n",
        "    #print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKnLOSW6iDFe",
        "outputId": "e782ac33-942b-46a5-d1ae-b4ebe444ede9"
      },
      "source": [
        "sentiment_predict('여기는 커피가 정말 너무 맛있어요 최고예요 직원도 친절해요')"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['여기다/Verb', '커피/Noun', '가/Josa', '정말/Noun', '너무/Adverb', '맛있다/Adjective', '최고/Noun', '예/Noun', '요/Noun', '직원/Noun', '도/Josa', '친절하다/Adjective']\n",
            "[[196, 7, 32, 8, 4, 10, 929, 36, 17, 18]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 196   7  32   8   4  10 929  36  17  18]]\n",
            "99.87% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tARDQ3WZiDHj",
        "outputId": "edfe60ea-87c1-46ff-807d-11c68c653ad2"
      },
      "source": [
        "sentiment_predict('더러워 직원이 불친절해요 짜증나 싫어')"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['더럽다/Adjective', '직원/Noun', '이/Josa', '불친절하다/Adjective', '짜증/Noun', '나/Noun', '싫다/Adjective']\n",
            "[[398, 17, 67, 601, 109, 390]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0 398  17  67 601 109 390]]\n",
            "2.41% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuNRvb6LhLCg",
        "outputId": "5ac84c81-aa91-4a7b-fa58-42610cfec249"
      },
      "source": [
        "sentiment_predict('그냥 저냥 보통이었어요 오늘 하루종일 기분이 우울해요')"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['그냥/Modifier', '저/Noun', '냥/Josa', '보통/Noun', '이다/Verb', '오늘/Noun', '하루/Noun', '종일/Noun', '기분/Noun', '이/Josa', '우울하다/Adjective']\n",
            "[[1014, 135, 367, 68, 317, 850, 1672, 98]]\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0 1014  135  367   68  317  850\n",
            "  1672   98]]\n",
            "45.76% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD-01ksahLEY",
        "outputId": "bba6a127-d5df-4a7f-bf30-7b67e8f476e2"
      },
      "source": [
        "sentiment_predict('맛있네요 예쁘네요 넓어요')"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['맛있다/Adjective', '예쁘다/Adjective', '넓다/Adjective']\n",
            "[[4, 63, 85]]\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  4 63 85]]\n",
            "187.72% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw5lP5tlhLGi",
        "outputId": "4c51b29f-0cb2-482c-89fa-6345ef9dab6d"
      },
      "source": [
        "sentiment_predict('공간이 넓어요')"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['공간/Noun', '이/Josa', '넓다/Adjective']\n",
            "[[61, 85]]\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0 61 85]]\n",
            "121.14% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bgEntMAhLI-",
        "outputId": "bdb7c056-7178-4356-de41-cbc5db4e8836"
      },
      "source": [
        "sentiment_predict('인테리어가 잘되어있고 케이크 맛있음')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인테리어/Noun', '가/Josa', '자다/Verb', '되어다/Verb', '있다/Adjective', '케이크/Noun', '맛있다/Adjective']\n",
            "[[58, 46, 148, 6, 30, 4]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0  58  46 148   6  30   4]]\n",
            "174.94% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMt2sbxShLLm",
        "outputId": "4b6e65d7-f0f9-4713-ad79-e8b5eaea18ff"
      },
      "source": [
        "sentiment_predict('ㅋㅋㅋ별로')"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ㅋㅋㅋ/KoreanParticle', '별로/Noun']\n",
            "[[34]]\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0 34]]\n",
            "6.40% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLW3iVD2jQML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1deb3343-2e79-4d99-e3a4-90089c7acf5e"
      },
      "source": [
        "sentiment_predict('애매해요')"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['애매하다/Adjective']\n",
            "[[1756]]\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0 1756]]\n",
            "98.54% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So8tq-polP4n"
      },
      "source": [
        ""
      ],
      "execution_count": 166,
      "outputs": []
    }
  ]
}