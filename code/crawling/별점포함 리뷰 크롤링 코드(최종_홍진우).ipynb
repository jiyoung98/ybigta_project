{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### 0\n",
      "#### 더파이홀\n",
      "연대 다닐 때 친구들 놀러오면 무조건 데려가는 곳이었음.(지금 위치 아니고 굴다리 옆에 있었을 당시) 오랜만에 와서 먹어보니 그때처럼 최고다 싶은 정도는 아니지만 얼그레이가나슈파이는 여전히 감동적...!/4\n",
      "맛있어용/4\n",
      "보통이에요/3\n",
      "신세계, 그러나 사악한 가격 ㅜㅜ 그리고 화장실 가면 화장실 나방? 맨날 있음....../3\n",
      "분위기도 좋고 맛있었습니다 파이 먹고싶을때 첫본째로 생각나는 것이에요  /5\n",
      "맛있음.친절 피넛초코ㅡ맛있음, 바삭 다음에 딴것도 먹어볼것. 재방문의사ㅡ85퍼/5\n",
      "초코파이.. 찐한 맛 ㅠ/5\n",
      "전 그냥 그랬어요 ...ㅎㅎ/3\n",
      "위생 관리 제발 하세요 코로나가 아니어도 기본적으로 음식 위에 뭘 덮어놔야 하는거 아니에요?/1\n",
      "예전부터 자주 갔어서 오늘도 포장하러 갔었는데, 위생에 정 떨어졌어요ㅠㅠ  로투스 타르트 주문해놓고 스콘도 시킬까 싶어서 봤는데, 스콘 들어있던 진열장? 안에 큰 날파리가 3-4마리 있었어요. 당연히 스콘 위에도 앉았고요.  좀 아닌 거 같아서 말씀드렸는데, 그 스콘들을 따로 빼는 게 아니라 그냥 맨손으로 (스콘에 맨손 닿음) 날파리 쫓으셨어요. 별 신경 .../1\n",
      "일부 메뉴들이 진열장 밖에 있어서 조금 위생적인 부분이 신경쓰이기는 하는데 파이는 맛있당 오레오말차가나슈 최고,,,, 항상 사람들이 붐벼서 요즘은 잘 못가겠지만 파이 존맛/4\n",
      "최고예요/5\n",
      "맛있었어요~ > </4\n",
      "보통이에요/3\n",
      "얼그레이 맛있어서 눈물 한방울/5\n",
      "밀크티가 너무 써요.... 따로 준 시럽 다 넣었는데도 쓴 맛이 나더라구요../4\n",
      "언제나 만족. 사람 밀도가 높은 것은 감내해야./5\n",
      "맛은 4점인데   분위기가 최악.... 정말 최악.... 시장통 + 구린 인테리어/3\n",
      "좋아요/4\n",
      "맛있다 인테리어가 먼지쌓이고 좀 정신사납지만 어차피 파이먹으러 가는 곳이니 괜찮다/5\n",
      "최고예요/5\n",
      "신촌에 친구들 놀러오면 무조건 데려가는 카페! 분위기도 나름 좋고 얼그레이 가나슈 존맛.. 파이 종류 왠만하면 다 맛있어요 음료는 그냥저냥입니당/5\n",
      "이제 화석학번이지만 (또륵) 연대생중에 파이홀 모르는 사람 없을 정도로 유명한 곳.. 신촌에 친구들 놀러오면 호불호 안갈리고 좋아해서 추천하는 카페 중 하나입니당 /4\n",
      "다른 파이는 다 평균치는 데..레몬머랭파이는 제발 절대 드시지마세요....제발...아이셔 10개씩 먹을 수 있는 분 아니면 먹지마세요. 솔직히 이렇게까지 유명할 일인가? 싶긴해요. 세네번 가긴했는데 유달리 맛있는 맛이라 찾아갈 정도는 아닙니다.  /2\n",
      "빵굽는 향이 기분좋다.은근넓다 좀 복작거리지만  파이도 맛있고 음료도 맛있지만 음료는 흠 완벽하진않다. 파이를 직접 다 굽는다 해서 흥미로웠는데 보기도 이쁘고 맛도 좋다 하지만 미치겠어~~~!!!하는 맛은 아닌들.주변에 갈일있으면 들릴만하다/4\n",
      "7월 중순 즈음에 방문했는데, 사람은 좀 많았지만 여깃 유명한데에는 이유가 있더라구요.. 맛이 최곱니다.. 메뉴명은 정확히 기억나지 않지만 레몬맛과 얼그레이 초코맛으로 골랐는데 정말 너어무 맛있었습니다...(*´︶`*) 신촌 가는데 맛있는 디저트를 먹고싶다! 하시면 여깁니다..b/5\n",
      "쿠키랑 커피랑 너무 잘어울려용...  분위기도 좋았어서 다음에 또 올것 같아용/4\n",
      "추가합니다) 파이홀 당신,, 쿠키가 맛있으면 그렇다고 말을 해줘야져,,,, 세상에 스모어 진짜 맛있었어요,,,, 사랑해,,, 원문) 맛 없진 않아요. 그냥 그렇습니다. 커피 파이 둘 다 그냥 그래요. 가격은 꽤 높은 편입니다. 여기도 웨이팅 하면서 먹을 곳은 아니고 가끔 생각나면 파이 한 조각씩 포장해가면 좋을 것 같아요. 신촌에 디저트집이 마땅한데가 없어.../3\n",
      "맛있는 파이집. 공간 대비 항상 사람이 많아 여유로운 분위기를 느끼기는 조금 어려운 것 같지만 맛있으니 갑니다. 얼그레이 가나슈와 말차가 제일 무난하고 깔끔하게 맛있는 메뉴에요./4\n",
      "좋아요/4\n",
      "무난하게 디저트 먹고싶을때 가기 좋음/4\n",
      "맛있는데 사람개많음/4\n",
      "얼그레이 가나슈 너무 맛있음 녹차가나슈인가 그건 진짜 별로 밍밍해요 녹차가 더 진해야함../4\n",
      "얼그레이가나슈가 맛있는. 공간은 별로/4\n",
      "보통이에요/3\n",
      "디저트 알못이라 그런지 잘 모르겠음 메뉴 탓인가 하고 전 메뉴 다 먹어봤는데도... 근데 맛없지는 않아요 말차인가 그건 클로렐라 맛 나서 0점 주고 싶음...../4\n",
      "다 맛있어요 브라우니와 얼그레이파이 강추/5\n",
      "최고예요/5\n",
      "유명하다 해서 왔는데 대기 시간 꽤나 있었고, 케익도 그저 그랬던 기억이./3\n",
      "너무 기대하고 가면 실망할지도/3\n",
      "사람이 많아서 좀 많이 기다렸어요. 하지만, 그만큼 맛이 너무 좋았어요!ㅠㅠ 사과파이 무척 좋아하는데 앞으로 여기만 갈것 같아요~ㅎㅎ/4\n",
      "애플파이에 아이스크림 올려달라했는데 첫번째 사진처럼 아이스크림 다 흘러내린 상태로 나옴 그래서 원래 이렇게 나오는거냐 물었더니 파이 데워서 그렇다고 함 근데 예전에 먹었을땐 두번째 사진처럼 깔끔하게 올려 나왔음 당연히 파이 데웠으니 어느정도 녹는건 이해하지만 첫번째 사진처럼 물처럼 녹은건;; 그럴거면 아이스크림을 왜 올려요.. 빡쳐서 다시 말하니까 파이 안.../2\n",
      "파이 맛있음, 항상 사람 많음. /4\n",
      "좋아요/4\n",
      "가끔 이상하리만치 원재료원재료스러운거 빼면 정말 괜찮아요. 홍차스콘이랑 얼그레이가나슈 딸기크림치즈(?) 존엄스러운 맛/4\n",
      "왜...?/1\n",
      "조금 아쉬워요/2\n",
      "올라가는 크림 양이 복불복이라 좀 별로지만 그래도 맛있다/4\n",
      "마싯어유 ~ 담엔 아이스크림 올려먹고싶어용/5\n",
      "예전만큼 못하다 스콘에 올라가는 크림이 참 맛있었는데 크림 올려주는 양이 줄었고 파이 크기도 줄었고  파이 맛도 스테디셀러 몇개 제외하고는 아쉬울때가 많아서 새로운 메뉴 시도하기 꺼려짐/2\n",
      "기념일날 맞춤파이제작했는데 앞으로 여기서만 할려구요! 맛도있고 예뻐요 /5\n",
      "조금 아쉬워요/2\n",
      "예전에는 다 특별하고 맛있어서 단골이었었는데 요즘은 파이들을 한번에 너무 많이 만드셔서 그런지 얼어서 나올때가 많고.. 금방 색도 변하고..ㅠ 장소가 너무 시끄럽고 별로예요... 지금의 퀄리티에 비해서는 가격도 너무 비싼 것 같아서 안찾게 되네요/2\n",
      "좋아요/4\n",
      "좋아요/4\n",
      "디저트 맛나지만 의자가 등받이 없어서 불편 ㅠ/5\n",
      "최고예요/5\n",
      "얼그레이 머시기 파이 정말 실망... 초콜렛무스?가 정말 별로였음 초콜렛부분 다남겼고 커피도 썩.../3\n",
      "괜찮은데 사람 너무많고 자리좁음 ㅜㅜ/3\n",
      "아늑하고 스콘이랑 디저트가 맛있네요! 직원들도 친절해요/5\n",
      "예전에 조그만 곳에 있을때는 평일에도 식사시간 이후에는 자리 거의못잡았음. 파이홀을 더 큰 곳으로 보내준 건물주께 ㄹㅇ 감사/5\n",
      "밤콩가루랑 호박이 개인적으로 제일 맛있다 오레오말차는 무난했고 얼그레이가나슈는 제일 유명하다는데 내입맛에는 제일 별로였다...크림이 너무 느끼하고 많고 얼그레이향도 딱히..?결국 그냥 크림 거의 걷어내고 먹음/5\n",
      "맛없음. 뭐가맛있다는건지? 그냥애들이먹기에 괜찮은가봄/1\n",
      "파이 맛있다구?? 잘모르겠다. ./2\n",
      "초콜릿 올려진 파이는 맛있었는데. 그 베리 어쩌구 파이는 너무 과했다 너무 달고 시고 너무 많이 올려져있어서 거의 남겼다../3\n",
      "비싸고 사람 많고 음료가 그저 그럼 근 데 파이가 이 모든걸 상쇄시킴... 파이 너무 맛있음...  근데 너무 비쌈... 울면서 먹음/4\n",
      "사람 (평일이었는데도) 오후에 진짜 많아요! ㅎㅎ 좌석 잡는 게 되게 자유로운 분위기인데 타이밍 잘 맞춰서 운 좋게 자리 잡았습니다(사실 2번째 시도) 파이 정말 맛있어요 ;)/5\n",
      "그닥/3\n",
      "실패없는 디저트 맛집/5\n",
      "청키한 애플 잔뜩 있는 애플파이 찾다가 요기와서 라즈베리루바브 삿어요! 크럼이 맛있어보여서ㅎㅎ 이집 파이 잘굽네요! 애플파이 없어서 못샀지만 담에 또 사러 가보려구여!/5\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=88.0.4324.182)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c451f00173c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-c451f00173c2>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#####\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c451f00173c2>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(place)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# 검색된 첫 페이지 장소 목록 크롤링하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mcrawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0msearch_area\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c451f00173c2>\u001b[0m in \u001b[0;36mcrawling\u001b[1;34m(place, place_lists)\u001b[0m\n\u001b[0;32m    144\u001b[0m                     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child('\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m')'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                     \u001b[0mextract_review\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m                     \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_link_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'다음'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 10페이지 이상으로 넘어가기 위한 다음 버튼 클릭\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c451f00173c2>\u001b[0m in \u001b[0;36mextract_review\u001b[1;34m(place_name)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \"\"\"\n\u001b[1;32m--> 679\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=88.0.4324.182)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('lang=ko_KR')\n",
    "path = 'C:/Users/82108/Desktop/chromedriver.exe'\n",
    "\n",
    "driver = webdriver.Chrome(path) # chromedriver 열기\n",
    "\n",
    "\n",
    "def main():\n",
    "    global driver, load_wb, review_num, searchList,place_name\n",
    "    \n",
    "    searchList = []\n",
    "\n",
    "    driver.implicitly_wait(4)  # 렌더링 될때까지 기다린다 4초\n",
    "    driver.get('https://map.kakao.com/?')  # 주소 가져오기\n",
    "\n",
    "    # 검색할 목록\n",
    "    place_infos = ['신촌 카페']\n",
    "\n",
    "    for i, place in enumerate(place_infos):\n",
    "        # delay\n",
    "        if i % 4 == 0 and i != 0:\n",
    "            sleep(5)\n",
    "        print(\"#####\", i)\n",
    "        search(place)\n",
    "        \n",
    "    driver.quit()   \n",
    "    print(searchList)    \n",
    "    print(\"finish\")\n",
    "    \n",
    "\n",
    "def search(place):\n",
    "    global driver, place_name\n",
    "\n",
    "    search_area = driver.find_element_by_xpath(\n",
    "        '//*[@id=\"search.keyword.query\"]')  # 검색 창\n",
    "    \n",
    "    search_area.send_keys(place)  # 검색어 입력\n",
    "    driver.find_element_by_xpath(\n",
    "        '//*[@id=\"search.keyword.query\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
    "    sleep(1)\n",
    "\n",
    "    # 검색된 정보가 있는 경우에만 탐색\n",
    "    # 1번 페이지 place list 읽기\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    place_lists = soup.select('.placelist > .PlaceItem')  # 검색된 장소 목록\n",
    "\n",
    "    # 검색된 첫 페이지 장소 목록 크롤링하기\n",
    "    crawling(place, place_lists)\n",
    "    print(place_lists)\n",
    "    search_area.clear()\n",
    "\n",
    "    # 우선 더보기 클릭해서 2페이지\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\n",
    "            '//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER)\n",
    "        sleep(1)\n",
    "\n",
    "        while True:\n",
    "            # 2~ 5페이지 읽기\n",
    "            for i in range(2, 6):\n",
    "                # 페이지 넘기기\n",
    "                xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "                driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER)\n",
    "                sleep(1)\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                place_lists = soup.select('.placelist > .PlaceItem')  # 장소 목록 list\n",
    "\n",
    "                print(place_lists)\n",
    "\n",
    "                crawling(place, place_lists)\n",
    "            \n",
    "            xPath = '//*[@id=\"info.search.page.next\"]'\n",
    "            driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER)\n",
    "            sleep(1)\n",
    "\n",
    "    except ElementNotInteractableException:\n",
    "        print('not found')\n",
    "    finally:\n",
    "        search_area.clear()\n",
    "\n",
    "def crawling(place, place_lists):\n",
    "    \"\"\"\n",
    "    페이지 목록을 받아서 크롤링 하는 함수\n",
    "    :param place: 리뷰 정보 찾을 장소이름\n",
    "    \"\"\"\n",
    "    while_flag = False\n",
    "    for i, place in enumerate(place_lists):\n",
    "        # 광고에 따라서 index 조정해야함\n",
    "        if i >= 3:\n",
    "            i += 1\n",
    "\n",
    "        place_name = place.select('.head_item > .tit_name > .link_name')[0].text  # place name\n",
    "        place_address = place.select('.info_item > .addr > p')[0].text  # place address\n",
    "\n",
    "        detail_page_xpath = '//*[@id=\"info.search.place.list\"]/li[' + str(i + 1) + ']/div[5]/div[4]/a[1]'\n",
    "        driver.find_element_by_xpath(detail_page_xpath).send_keys(Keys.ENTER)\n",
    "        driver.switch_to.window(driver.window_handles[-1])  # 상세정보 탭으로 변환\n",
    "        sleep(1)\n",
    "\n",
    "        print('####', place_name)\n",
    "\n",
    "        # 첫 페이지\n",
    "        extract_review(place_name)\n",
    "\n",
    "        # 2-5 페이지\n",
    "        idx = 3\n",
    "        try:\n",
    "            page_num = len(driver.find_elements_by_class_name('link_page')) # 페이지 수 찾기\n",
    "            for i in range(page_num-1):\n",
    "                # css selector를 이용해 페이지 버튼 누르기\n",
    "                driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                sleep(1)\n",
    "                extract_review(place_name)\n",
    "                idx += 1\n",
    "            driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 5페이지가 넘는 경우 다음 버튼 누르기\n",
    "            sleep(1)\n",
    "            extract_review(place_name) # 리뷰 추출\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            print(\"no review in crawling\")\n",
    "\n",
    "        # 그 이후 페이지\n",
    "        while True:\n",
    "            idx = 4\n",
    "            try:\n",
    "                page_num = len(driver.find_elements_by_class_name('link_page'))\n",
    "                for i in range(page_num-1):\n",
    "                    driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                    sleep(1)\n",
    "                    extract_review(place_name)\n",
    "                    idx += 1\n",
    "                driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 10페이지 이상으로 넘어가기 위한 다음 버튼 클릭\n",
    "                sleep(1)\n",
    "                extract_review(place_name) # 리뷰 추출\n",
    "            except (NoSuchElementException, ElementNotInteractableException):\n",
    "                print(\"no review in crawling\")\n",
    "                break\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])  # 검색 탭으로 전환\n",
    "\n",
    "def extract_review(place_name):\n",
    "    global driver\n",
    "\n",
    "    ret = True\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 첫 페이지 리뷰 목록 찾기\n",
    "    review_lists = soup.select('.list_evaluation > li')   \n",
    "    \n",
    "    # 리뷰가 있는 경우\n",
    "    if len(review_lists) != 0:\n",
    "        \n",
    "        for i, review in enumerate(review_lists):\n",
    "            \n",
    "            comment = review.select('.txt_comment > span') # 리뷰\n",
    "            rating = review.select('.grade_star > em') # 별점\n",
    "            val = ''\n",
    "            if len(comment) != 0:\n",
    "                innersearchList = []\n",
    "                if len(rating) != 0:\n",
    "                    val = comment[0].text + '/' + rating[0].text.replace('점', '')\n",
    "                    innersearchList.append(place_name)    \n",
    "                    innersearchList.append(comment[0].text)\n",
    "                    innersearchList.append(rating[0].text)\n",
    "                else:\n",
    "                    val = comment[0].text + '/0'\n",
    "                    innersearchList.append(place_name)    \n",
    "                    innersearchList.append(comment[0].text)\n",
    "                    innersearchList.append(0)\n",
    "                print(val)\n",
    "                \n",
    "                searchList.append(innersearchList)\n",
    "    else:\n",
    "        print('no review in extract')\n",
    "        ret = False\n",
    "    return ret\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(searchList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1361 entries, 0 to 1360\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       1361 non-null   object\n",
      " 1   1       1361 non-null   object\n",
      " 2   2       1361 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 32.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>분위기도 좋고 커피도 맛있고  공간이 머쉿다~</td>\n",
       "      <td>4점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>최고예요</td>\n",
       "      <td>5점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>좋아요</td>\n",
       "      <td>4점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>공부하기 좋고 넓어서 애용하는 곳</td>\n",
       "      <td>5점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>좋아요</td>\n",
       "      <td>4점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>이가격에 이공간 이맛 끄덕끄덕</td>\n",
       "      <td>5점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>최고예요</td>\n",
       "      <td>5점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>음료보다 인테리어가 더 인상깊어요 넓고 공간도 다양하게 있습니다 꼭대기층 테라스자리...</td>\n",
       "      <td>4점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>요 근처 회사 다니는 사람이에요. 커피 맛은 대단히 맛있지도 별로지도 아닌 보통의 ...</td>\n",
       "      <td>3점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>맥심플랜트</td>\n",
       "      <td>커피맛 최고! 아메리카노 골든스카이 + 글래머러스 펭귄 케익 최고!!  공간 다양 ...</td>\n",
       "      <td>4점</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1   2\n",
       "0  맥심플랜트                         분위기도 좋고 커피도 맛있고  공간이 머쉿다~   4점\n",
       "1  맥심플랜트                                               최고예요  5점\n",
       "2  맥심플랜트                                                좋아요  4점\n",
       "3  맥심플랜트                                 공부하기 좋고 넓어서 애용하는 곳  5점\n",
       "4  맥심플랜트                                                좋아요  4점\n",
       "5  맥심플랜트                                   이가격에 이공간 이맛 끄덕끄덕  5점\n",
       "6  맥심플랜트                                               최고예요  5점\n",
       "7  맥심플랜트  음료보다 인테리어가 더 인상깊어요 넓고 공간도 다양하게 있습니다 꼭대기층 테라스자리...  4점\n",
       "8  맥심플랜트  요 근처 회사 다니는 사람이에요. 커피 맛은 대단히 맛있지도 별로지도 아닌 보통의 ...  3점\n",
       "9  맥심플랜트  커피맛 최고! 아메리카노 골든스카이 + 글래머러스 펭귄 케익 최고!!  공간 다양 ...  4점"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"왕십리 cafe_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cafe_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f4bf57f8af6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcafe_namelist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcafe_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcafe_namelist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cafe_list' is not defined"
     ]
    }
   ],
   "source": [
    "cafe_namelist = cafe_list.drop_duplicates()\n",
    "cafe_namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_namelist = pd.DataFrame(cafe_namelist)\n",
    "cafe_namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_namelist['cafe_name'] = \"강남카페 \" + cafe_namelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_namelist.drop([0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_namelist.to_csv(\"cafe_namelist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
