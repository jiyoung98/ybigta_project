{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modeling적용2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm4yhW-E-_oM",
        "outputId": "8a544608-d9d9-4c5c-a851-fe5f3bc0c49e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ITIjgBn_jBY"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8weUdYeWbZw"
      },
      "source": [
        "max_words=3584\r\n",
        "tokenizer = Tokenizer(num_words=max_words)\r\n",
        "\r\n",
        "import json\r\n",
        "\r\n",
        "with open('/content/drive/MyDrive/Ybigta/신입기수 프로젝트/model/wordIndex.json') as json_file:\r\n",
        "  word_index = json.load(json_file)\r\n",
        "  tokenizer.word_index = word_index\r\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FwfWqxC_AcP"
      },
      "source": [
        "loaded_model = load_model('/content/drive/MyDrive/Ybigta/신입기수 프로젝트/model/lstm_model2.h5')"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aexwNdH_Aid",
        "outputId": "07625d67-3482-42a5-de1c-becc0fd36474"
      },
      "source": [
        "!pip install konlpy\r\n",
        "from konlpy.tag import Okt\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tunMpV14ALhd"
      },
      "source": [
        "okt = Okt()\r\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\r\n",
        "\r\n",
        "\r\n",
        "max_len = 10"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9CGtVuG_AfO"
      },
      "source": [
        "def sentiment_predict(new_sentence):\r\n",
        "  new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\r\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\r\n",
        "  print(new_sentence)\r\n",
        "  #tokenizer.fit_on_texts(new_sentence)\r\n",
        "  new_list = []\r\n",
        "  ex_morpheme = \" \".join(new_sentence)\r\n",
        "  new_list.append(ex_morpheme)\r\n",
        "  print(new_list)\r\n",
        "  sequences = tokenizer.texts_to_sequences(new_list)\r\n",
        "  x_test = pad_sequences(sequences, maxlen=max_len)\r\n",
        "\r\n",
        "  score = loaded_model.predict(x_test)\r\n",
        "  print(score)\r\n",
        "  if(score > 0.5):\r\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\r\n",
        "  else:\r\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BvIL3RU_AqW"
      },
      "source": [
        "# 참고로 ex_morpheme은 ['토큰1 토큰 토큰 토큰 토큰'] 의 형태\r\n",
        "ex_morpheme = ['여기 커피 정말 맛있다 최고 직원 친절하다']\r\n",
        "ex1 = ['더럽다 직원 불친절하다 짜증나다 싫다 맛없다']"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQPvkbISWX1S",
        "outputId": "26e6d912-57cf-4a57-a219-939c4ec6cac1"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(ex_morpheme)\r\n",
        "x_test = pad_sequences(sequences, maxlen=max_len)\r\n",
        "\r\n",
        "value_predicted = loaded_model.predict(x_test)\r\n",
        "\r\n",
        "print(value_predicted)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6216095]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKS0MzcgWX4p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "MWcxaBTq_Aso",
        "outputId": "f585c141-e42d-4616-c0fc-7d924ba8361d"
      },
      "source": [
        "sentiment_predict('여기 커피가 정말 너무 맛있어요 최고예요 직원도 친절해요')"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['여기', '커피', '정말', '너무', '맛있다', '최고', '예요', '직원', '친절하다']\n",
            "['여기 커피 정말 너무 맛있다 최고 예요 직원 친절하다']\n",
            "[[0.6216095]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-165-534a3b59a9bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'여기 커피가 정말 너무 맛있어요 최고예요 직원도 친절해요'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-164-069600eb468a>\u001b[0m in \u001b[0;36msentiment_predict\u001b[0;34m(new_sentence)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:.2f}% 확률로 부정 리뷰입니다.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygu9e38iAJuj",
        "outputId": "8765b5bf-870c-4aa1-deb5-cab4fde5ad1d"
      },
      "source": [
        "sentiment_predict('더러워 직원이 불친절해요 짜증나 싫어')"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['더럽다', '직원', '불친절하다', '짜증나다', '싫다']\n",
            "[[2, 1, 3, 4, 5]]\n",
            "[[0 0 0 0 0 2 1 3 4 5]]\n",
            "0.9652442932128906\n",
            "96.52% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "104qRUX3BGmz"
      },
      "source": [
        ""
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM_svjhdBGwC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}